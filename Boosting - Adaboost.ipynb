{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code is just to avoid unnecessary warning - can be copy pasted\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = (r\"C:\\Users\\Anjali.Rajvanshi\\Desktop\\Data\\heart-disease-uci\\heart.csv\")\n",
    "df = pd.read_csv(path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null int64\n",
      "sex         303 non-null int64\n",
      "cp          303 non-null int64\n",
      "trestbps    303 non-null int64\n",
      "chol        303 non-null int64\n",
      "fbs         303 non-null int64\n",
      "restecg     303 non-null int64\n",
      "thalach     303 non-null int64\n",
      "exang       303 non-null int64\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null int64\n",
      "ca          303 non-null int64\n",
      "thal        303 non-null int64\n",
      "target      303 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Only 14 attributes used:\n",
    "1. age - age in years\n",
    "2. sex - 1 = male; 0 = female\n",
    "3. cp -  chest pain type\n",
    "         Value 1: typical angina\n",
    "         Value 2: atypical angina\n",
    "         Value 3: non-anginal pain\n",
    "         Value 4: asymptomatic\n",
    "4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. chol - serum cholestoral in mg/dl\n",
    "6. fbs - fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
    "7. restecg - resting electrocardiographic results\n",
    "             Value 0: normal\n",
    "             Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "             Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "8. thalach - maximum heart rate achieved\n",
    "9. exang - exercise induced angina (1 = yes; 0 = no)\n",
    "10. oldpeak -  ST depression induced by exercise relative to rest\n",
    "11. slope - the slope of the peak exercise ST segment\n",
    "            Value 1: upsloping\n",
    "            Value 2: flat\n",
    "            Value 3: downsloping\n",
    "12. ca - number of major vessels (0-3) colored by flourosopy\n",
    "13. thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. target - diagnosis of heart disease (angiographic disease status)\n",
    "             Value 0: < 50% diameter narrowing\n",
    "             Value 1: > 50% diameter narrowing\n",
    "            (in any major vessel: attributes 59 through 68 are vessels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the following values to ccategorical variables\n",
    "# sex, cp, restecg, exang, slope, thal, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex']=df['sex'].astype(str)\n",
    "df['cp']=df['cp'].astype(str)\n",
    "df['restecg']=df['restecg'].astype(str)\n",
    "df['exang']=df['exang'].astype(str)\n",
    "df['slope']=df['slope'].astype(str)\n",
    "df['thal']=df['thal'].astype(str)\n",
    "df['target']=df['target'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null int64\n",
      "sex         303 non-null object\n",
      "cp          303 non-null object\n",
      "trestbps    303 non-null int64\n",
      "chol        303 non-null int64\n",
      "fbs         303 non-null int64\n",
      "restecg     303 non-null object\n",
      "thalach     303 non-null int64\n",
      "exang       303 non-null object\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null object\n",
      "ca          303 non-null int64\n",
      "thal        303 non-null object\n",
      "target      303 non-null object\n",
      "dtypes: float64(1), int64(6), object(7)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies for the object datatype except for the response variable target\n",
    "df = pd.get_dummies(df, prefix=['sex', 'cp', 'restecg', 'exang', 'slope', 'thal'], \n",
    "               columns=['sex', 'cp', 'restecg', 'exang', 'slope', 'thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 26)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 26 columns and 303 rows\n",
    "# No missing values\n",
    "# Since we are considering ensembles using tree as the base classifier, handling outliers is not necessary\n",
    "# This is a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the model building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>target</th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2</th>\n",
       "      <th>exang_0</th>\n",
       "      <th>exang_1</th>\n",
       "      <th>slope_0</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "      <th>thal_0</th>\n",
       "      <th>thal_1</th>\n",
       "      <th>thal_2</th>\n",
       "      <th>thal_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  trestbps  chol  fbs  thalach  oldpeak  ca target  sex_0  sex_1  ...  \\\n",
       "0   63       145   233    1      150      2.3   0      1      0      1  ...   \n",
       "1   37       130   250    0      187      3.5   0      1      0      1  ...   \n",
       "2   41       130   204    0      172      1.4   0      1      1      0  ...   \n",
       "3   56       120   236    0      178      0.8   0      1      0      1  ...   \n",
       "4   57       120   354    0      163      0.6   0      1      1      0  ...   \n",
       "\n",
       "   restecg_2  exang_0  exang_1  slope_0  slope_1  slope_2  thal_0  thal_1  \\\n",
       "0          0        1        0        1        0        0       0       1   \n",
       "1          0        1        0        1        0        0       0       0   \n",
       "2          0        1        0        0        0        1       0       0   \n",
       "3          0        1        0        0        0        1       0       0   \n",
       "4          0        0        1        0        0        1       0       0   \n",
       "\n",
       "   thal_2  thal_3  \n",
       "0       0       0  \n",
       "1       1       0  \n",
       "2       1       0  \n",
       "3       1       0  \n",
       "4       1       0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test/validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 25)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 25)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaClassifier = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = adaClassifier.predict_proba(X_test)[:,1]\n",
    "#adaClassifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161290322580645"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on AdaBoostClassifier in module sklearn.ensemble.weight_boosting object:\n",
      "\n",
      "class AdaBoostClassifier(BaseWeightBoosting, sklearn.base.ClassifierMixin)\n",
      " |  AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
      " |  \n",
      " |  An AdaBoost classifier.\n",
      " |  \n",
      " |  An AdaBoost [1] classifier is a meta-estimator that begins by fitting a\n",
      " |  classifier on the original dataset and then fits additional copies of the\n",
      " |  classifier on the same dataset but where the weights of incorrectly\n",
      " |  classified instances are adjusted such that subsequent classifiers focus\n",
      " |  more on difficult cases.\n",
      " |  \n",
      " |  This class implements the algorithm known as AdaBoost-SAMME [2].\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <adaboost>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  base_estimator : object, optional (default=None)\n",
      " |      The base estimator from which the boosted ensemble is built.\n",
      " |      Support for sample weighting is required, as well as proper\n",
      " |      ``classes_`` and ``n_classes_`` attributes. If ``None``, then\n",
      " |      the base estimator is ``DecisionTreeClassifier(max_depth=1)``\n",
      " |  \n",
      " |  n_estimators : integer, optional (default=50)\n",
      " |      The maximum number of estimators at which boosting is terminated.\n",
      " |      In case of perfect fit, the learning procedure is stopped early.\n",
      " |  \n",
      " |  learning_rate : float, optional (default=1.)\n",
      " |      Learning rate shrinks the contribution of each classifier by\n",
      " |      ``learning_rate``. There is a trade-off between ``learning_rate`` and\n",
      " |      ``n_estimators``.\n",
      " |  \n",
      " |  algorithm : {'SAMME', 'SAMME.R'}, optional (default='SAMME.R')\n",
      " |      If 'SAMME.R' then use the SAMME.R real boosting algorithm.\n",
      " |      ``base_estimator`` must support calculation of class probabilities.\n",
      " |      If 'SAMME' then use the SAMME discrete boosting algorithm.\n",
      " |      The SAMME.R algorithm typically converges faster than SAMME,\n",
      " |      achieving a lower test error with fewer boosting iterations.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimators_ : list of classifiers\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : array of shape = [n_classes]\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  n_classes_ : int\n",
      " |      The number of classes.\n",
      " |  \n",
      " |  estimator_weights_ : array of floats\n",
      " |      Weights for each estimator in the boosted ensemble.\n",
      " |  \n",
      " |  estimator_errors_ : array of floats\n",
      " |      Classification error for each estimator in the boosted\n",
      " |      ensemble.\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances if supported by the ``base_estimator``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import AdaBoostClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
      " |  >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE\n",
      " |  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      " |          learning_rate=1.0, n_estimators=100, random_state=0)\n",
      " |  >>> clf.feature_importances_  # doctest: +ELLIPSIS\n",
      " |  array([0.28..., 0.42..., 0.14..., 0.16...])\n",
      " |  >>> clf.predict([[0, 0, 0, 0]])\n",
      " |  array([1])\n",
      " |  >>> clf.score(X, y)  # doctest: +ELLIPSIS\n",
      " |  0.983...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  AdaBoostRegressor, GradientBoostingClassifier,\n",
      " |  sklearn.tree.DecisionTreeClassifier\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] Y. Freund, R. Schapire, \"A Decision-Theoretic Generalization of\n",
      " |         on-Line Learning and an Application to Boosting\", 1995.\n",
      " |  \n",
      " |  .. [2] J. Zhu, H. Zou, S. Rosset, T. Hastie, \"Multi-class AdaBoost\", 2009.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AdaBoostClassifier\n",
      " |      BaseWeightBoosting\n",
      " |      sklearn.ensemble.base.BaseEnsemble\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Compute the decision function of ``X``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : array, shape = [n_samples, k]\n",
      " |          The decision function of the input samples. The order of\n",
      " |          outputs is the same of that of the `classes_` attribute.\n",
      " |          Binary classification is a special cases with ``k == 1``,\n",
      " |          otherwise ``k==n_classes``. For binary classification,\n",
      " |          values closer to -1 or 1 mean more like the first or second\n",
      " |          class in ``classes_``, respectively.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a boosted classifier from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      y : array-like of shape = [n_samples]\n",
      " |          The target values (class labels).\n",
      " |      \n",
      " |      sample_weight : array-like of shape = [n_samples], optional\n",
      " |          Sample weights. If None, the sample weights are initialized to\n",
      " |          ``1 / n_samples``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict classes for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is computed as the weighted mean\n",
      " |      prediction of the classifiers in the ensemble.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples]\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the weighted mean predicted class log-probabilities of the classifiers\n",
      " |      in the ensemble.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes]\n",
      " |          The class probabilities of the input samples. The order of\n",
      " |          outputs is the same of that of the `classes_` attribute.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample is computed as\n",
      " |      the weighted mean predicted class probabilities of the classifiers\n",
      " |      in the ensemble.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes]\n",
      " |          The class probabilities of the input samples. The order of\n",
      " |          outputs is the same of that of the `classes_` attribute.\n",
      " |  \n",
      " |  staged_decision_function(self, X)\n",
      " |      Compute decision function of ``X`` for each boosting iteration.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each boosting iteration.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : generator of array, shape = [n_samples, k]\n",
      " |          The decision function of the input samples. The order of\n",
      " |          outputs is the same of that of the `classes_` attribute.\n",
      " |          Binary classification is a special cases with ``k == 1``,\n",
      " |          otherwise ``k==n_classes``. For binary classification,\n",
      " |          values closer to -1 or 1 mean more like the first or second\n",
      " |          class in ``classes_``, respectively.\n",
      " |  \n",
      " |  staged_predict(self, X)\n",
      " |      Return staged predictions for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is computed as the weighted mean\n",
      " |      prediction of the classifiers in the ensemble.\n",
      " |      \n",
      " |      This generator method yields the ensemble prediction after each\n",
      " |      iteration of boosting and therefore allows monitoring, such as to\n",
      " |      determine the prediction on a test set after each boost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape = [n_samples, n_features]\n",
      " |          The input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : generator of array, shape = [n_samples]\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  staged_predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample is computed as\n",
      " |      the weighted mean predicted class probabilities of the classifiers\n",
      " |      in the ensemble.\n",
      " |      \n",
      " |      This generator method yields the ensemble predicted class probabilities\n",
      " |      after each iteration of boosting and therefore allows monitoring, such\n",
      " |      as to determine the predicted class probabilities on a test set after\n",
      " |      each boost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : generator of array, shape = [n_samples]\n",
      " |          The class probabilities of the input samples. The order of\n",
      " |          outputs is the same of that of the `classes_` attribute.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseWeightBoosting:\n",
      " |  \n",
      " |  staged_score(self, X, y, sample_weight=None)\n",
      " |      Return staged scores for X, y.\n",
      " |      \n",
      " |      This generator method yields the ensemble score after each iteration of\n",
      " |      boosting and therefore allows monitoring, such as to determine the\n",
      " |      score on a test set after each boost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      z : float\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseWeightBoosting:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances (the higher, the more important the\n",
      " |         feature).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble.base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Returns iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(adaClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaClassifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost model with parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the parameter grid\n",
    "# parameter grid\n",
    "param_grid = {\"base_estimator__max_depth\" : [2, 5],\n",
    "              \"learning_rate\": [0.1, 0.3, 0.5, 0.6, 0.8],\n",
    "              \"n_estimators\": [200, 400, 600]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__max_depth': [2, 5],\n",
       " 'learning_rate': [0.1, 0.3, 0.5, 0.6, 0.8],\n",
       " 'n_estimators': [200, 400, 600]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "grid_search_ABC = GridSearchCV(estimator=ABC, cv = 3, param_grid=param_grid, scoring = 'roc_auc', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=200, score=0.867, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=200, score=0.791, total=   0.7s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=200, score=0.820, total=   0.7s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=400, score=0.865, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=400, score=0.791, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=400, score=0.829, total=   1.1s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=600, score=0.841, total=   1.8s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=600, score=0.784, total=   1.8s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.1, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.1, n_estimators=600, score=0.832, total=   1.9s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=200, score=0.855, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=200, score=0.798, total=   0.7s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=200, score=0.843, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=400, score=0.856, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=400, score=0.781, total=   1.1s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=400, score=0.827, total=   1.1s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=600, score=0.840, total=   2.0s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=600, score=0.786, total=   1.8s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.3, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.3, n_estimators=600, score=0.828, total=   1.8s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=200, score=0.855, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=200, score=0.796, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=200, score=0.860, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=400, score=0.836, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=400, score=0.786, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=400, score=0.844, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=600, score=0.862, total=   1.7s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=600, score=0.774, total=   1.8s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.5, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.5, n_estimators=600, score=0.835, total=   1.8s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=200, score=0.832, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=200, score=0.773, total=   0.7s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=200, score=0.843, total=   0.7s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=400, score=0.851, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=400, score=0.778, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=400, score=0.827, total=   1.1s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=600, score=0.859, total=   1.7s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=600, score=0.775, total=   1.8s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.6, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.6, n_estimators=600, score=0.822, total=   1.8s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=200, score=0.835, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=200, score=0.771, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=200, score=0.853, total=   0.6s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=400, score=0.853, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=400, score=0.760, total=   1.2s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=400, score=0.823, total=   1.1s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=600, score=0.840, total=   1.9s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=600, score=0.772, total=   1.7s\n",
      "[CV] base_estimator__max_depth=2, learning_rate=0.8, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=2, learning_rate=0.8, n_estimators=600, score=0.830, total=   1.6s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=200, score=0.794, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=200, score=0.781, total=   0.8s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=200, score=0.781, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=400, score=0.781, total=   1.4s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=400, score=0.827, total=   1.3s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=400, score=0.815, total=   1.3s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=600, score=0.821, total=   2.0s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=600, score=0.762, total=   1.8s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.1, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.1, n_estimators=600, score=0.797, total=   2.2s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=200, score=0.764, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=200, score=0.793, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=200, score=0.707, total=   0.8s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=400, score=0.774, total=   1.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=400, score=0.759, total=   1.2s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=400, score=0.700, total=   1.2s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=600, score=0.798, total=   2.0s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=600, score=0.819, total=   2.1s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.3, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.3, n_estimators=600, score=0.679, total=   2.2s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=200, score=0.859, total=   0.6s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=200, score=0.796, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=200, score=0.773, total=   0.6s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=400, score=0.865, total=   1.6s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=400, score=0.775, total=   1.4s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=400, score=0.810, total=   1.3s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=600, score=0.855, total=   2.0s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=600, score=0.867, total=   2.0s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.5, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.5, n_estimators=600, score=0.761, total=   2.2s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=200, score=0.870, total=   0.8s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=200, score=0.834, total=   0.8s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=200, score=0.773, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=400, score=0.862, total=   1.4s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=400, score=0.777, total=   1.4s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=400, score=0.807, total=   1.6s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=600, score=0.849, total=   2.0s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=600, score=0.788, total=   2.0s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.6, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.6, n_estimators=600, score=0.780, total=   2.1s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=200, score=0.862, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=200, score=0.823, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=200 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=200, score=0.822, total=   0.7s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=400, score=0.855, total=   1.3s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=400, score=0.824, total=   1.3s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=400 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=400, score=0.841, total=   1.2s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=600, score=0.852, total=   2.1s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=600, score=0.820, total=   2.2s\n",
      "[CV] base_estimator__max_depth=5, learning_rate=0.8, n_estimators=600 \n",
      "[CV]  base_estimator__max_depth=5, learning_rate=0.8, n_estimators=600, score=0.846, total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                presort=False,\n",
       "                                                                                random_state=None,\n",
       "                                                                                splitter='best'),\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'base_estimator__max_depth': [2, 5],\n",
       "                         'learning_rate': [0.1, 0.3, 0.5, 0.6, 0.8],\n",
       "                         'n_estimators': [200, 400, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_ABC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(grid_search_ABC.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_base_estimator__max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.18641</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.082005</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>400</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.854938</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.840635</td>\n",
       "      <td>0.839879</td>\n",
       "      <td>0.012637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "28        1.18641      0.019561         0.082005        0.009574   \n",
       "\n",
       "   param_base_estimator__max_depth param_learning_rate param_n_estimators  \\\n",
       "28                               5                 0.8                400   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "28  {'base_estimator__max_depth': 5, 'learning_rat...           0.854938   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "28           0.824074           0.840635         0.839879        0.012637   \n",
       "\n",
       "    rank_test_score  \n",
       "28                1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.loc[cv_results['rank_test_score']==1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), learning_rate=0.8, n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=5,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.8, n_estimators=400, random_state=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ABC.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9064516129032258"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
